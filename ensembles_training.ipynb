{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "import torch\n",
    "from lightning.fabric import Fabric\n",
    "from lightning.pytorch.utilities.seed import isolate_rng\n",
    "from sheeprl.algos.dreamer_v3.utils import init_weights, uniform_init_weights\n",
    "from sheeprl.models.models import MLP\n",
    "from sheeprl.utils.utils import dotdict\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from sheeprl.utils.env import make_env\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from sheeprl.data.buffers import EnvIndependentReplayBuffer, SequentialReplayBuffer\n",
    "import os\n",
    "from sheeprl.utils.distribution import (\n",
    "    MSEDistribution\n",
    ")\n",
    "\n",
    "# path of your checkpoint\n",
    "ckpt_path = pathlib.Path(r\"C:\\Users\\user\\Documents\\MasterThesis\\sheep RL\\sheeprl-main\\logs\\runs\\p2e_dv3_exploration\\PongNoFrameskip-v4\\2024-07-11_03-11-12_p2e_dv3_exploration_PongNoFrameskip-v4_42\\version_0\\checkpoint\\ckpt_80000_0.ckpt\")\n",
    "\n",
    "seed = 12\n",
    "fabric = Fabric(accelerator=\"cuda\", devices=1)\n",
    "fabric.launch()\n",
    "#state = fabric.load(ckpt_path)\n",
    "cfg = dotdict(OmegaConf.to_container(OmegaConf.load(ckpt_path.parent.parent / \"config.yaml\"), resolve=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\RL\\Lib\\site-packages\\gymnasium\\experimental\\wrappers\\rendering.py:166: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\user\\Documents\\MasterThesis\\sheep RL\\sheeprl-main\\notebooks\\imagination\\imagination_videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "# Environment setup\n",
    "vectorized_env = gym.vector.SyncVectorEnv if cfg.env.sync_env else gym.vector.AsyncVectorEnv\n",
    "envs = vectorized_env(\n",
    "    [\n",
    "        make_env(\n",
    "            cfg,\n",
    "            cfg.seed + 0 * cfg.env.num_envs + i,\n",
    "            0 * cfg.env.num_envs,\n",
    "            \"./imagination\",\n",
    "            \"imagination\",\n",
    "            vector_env_idx=i,\n",
    "        )\n",
    "        for i in range(cfg.env.num_envs)\n",
    "    ]\n",
    ")\n",
    "action_space = envs.single_action_space\n",
    "observation_space = envs.single_observation_space\n",
    "\n",
    "is_continuous = isinstance(action_space, gym.spaces.Box)\n",
    "is_multidiscrete = isinstance(action_space, gym.spaces.MultiDiscrete)\n",
    "actions_dim = tuple(\n",
    "    action_space.shape if is_continuous else (action_space.nvec.tolist() if is_multidiscrete else [action_space.n])\n",
    ")\n",
    "clip_rewards_fn = lambda r: np.tanh(r) if cfg.env.clip_rewards else r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 43\n",
      "Seed set to 44\n",
      "Seed set to 45\n"
     ]
    }
   ],
   "source": [
    "# The number of environments is set to 1\n",
    "cfg.env.num_envs = 4\n",
    "\n",
    "ens_list = []\n",
    "cfg_ensembles = cfg.algo.ensembles\n",
    "cfg_ensembles.n = 4\n",
    "ensembles_ln_cls = hydra.utils.get_class(cfg_ensembles.layer_norm.cls)\n",
    "with isolate_rng():\n",
    "    for i in range(cfg_ensembles.n):\n",
    "        fabric.seed_everything(cfg.seed + i)\n",
    "        ens_list.append(\n",
    "            MLP(\n",
    "                input_dims=int(\n",
    "                    sum(actions_dim)\n",
    "                    + cfg.algo.world_model.recurrent_model.recurrent_state_size\n",
    "                    + cfg.algo.world_model.stochastic_size * cfg.algo.world_model.discrete_size\n",
    "                ),\n",
    "                output_dim=cfg.algo.world_model.stochastic_size * cfg.algo.world_model.discrete_size,\n",
    "                hidden_sizes=[cfg_ensembles.dense_units] * cfg_ensembles.mlp_layers,\n",
    "                activation=hydra.utils.get_class(cfg_ensembles.dense_act),\n",
    "                flatten_dim=None,\n",
    "                layer_args={\"bias\": ensembles_ln_cls == nn.Identity},\n",
    "                norm_layer=ensembles_ln_cls,\n",
    "                norm_args={\n",
    "                    **cfg_ensembles.layer_norm.kw,\n",
    "                    \"normalized_shape\": cfg_ensembles.dense_units,\n",
    "                },\n",
    "            ).apply(init_weights)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles = nn.ModuleList(ens_list)\n",
    "for i in range(len(ensembles)):\n",
    "    ensembles[i] = fabric.setup_module(ensembles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.checkpoint.resume_from:\n",
    "    state = fabric.load(cfg.checkpoint.resume_from)\n",
    "\n",
    "world_size = fabric.world_size\n",
    "buffer_size = cfg.buffer.size // int(cfg.env.num_envs * world_size) if not cfg.dry_run else 4\n",
    "rb = EnvIndependentReplayBuffer(\n",
    "    buffer_size,\n",
    "    n_envs=cfg.env.num_envs,\n",
    "    memmap=cfg.buffer.memmap,\n",
    "    memmap_dir=os.path.join(\".\", \"memmap_buffer\", f\"rank_{fabric.global_rank}\"),\n",
    "    buffer_cls=SequentialReplayBuffer,\n",
    ")\n",
    "\n",
    "if cfg.checkpoint.resume_from and cfg.buffer.checkpoint:\n",
    "    if isinstance(state[\"rb\"], list) and world_size == len(state[\"rb\"]):\n",
    "        rb = state[\"rb\"][fabric.global_rank]\n",
    "    elif isinstance(state[\"rb\"], EnvIndependentReplayBuffer):\n",
    "        rb = state[\"rb\"]\n",
    "    else:\n",
    "        raise RuntimeError(f\"Given {len(state['rb'])}, but {world_size} processes are instantiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pathlib\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from lightning.fabric import Fabric\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "from sheeprl.algos.dreamer_v3.agent import build_agent\n",
    "#from sheeprl.algos.p2e_dv3.agent import build_agent\n",
    "from sheeprl.data.buffers import SequentialReplayBuffer\n",
    "from sheeprl.utils.env import make_env\n",
    "from sheeprl.utils.utils import dotdict\n",
    "\n",
    "# path of your checkpoint\n",
    "ckpt_path = pathlib.Path(r\"C:\\Users\\user\\Documents\\MasterThesis\\sheep RL\\sheeprl-main\\logs\\runs\\dreamer_v3\\PongNoFrameskip-v4\\2024-06-17_00-51-22_dreamer_v3_PongNoFrameskip-v4_42\\version_0\\checkpoint\\ckpt_120000_0.ckpt\")\n",
    "seed = 12\n",
    "# fabric_model = Fabric(accelerator=\"cuda\", devices=1)\n",
    "# fabric_model.launch()\n",
    "model_state = fabric.load(ckpt_path)\n",
    "model_cfg = dotdict(OmegaConf.to_container(OmegaConf.load(ckpt_path.parent.parent / \"config.yaml\"), resolve=True))\n",
    "\n",
    "# The number of environments is set to 1\n",
    "# model_cfg.env.num_envs = 1\n",
    "# torch.set_float32_matmul_precision('medium')\n",
    "# envs = gym.vector.SyncVectorEnv(\n",
    "#     [\n",
    "#         make_env(\n",
    "#             model_cfg,\n",
    "#             model_cfg.seed + 0 * model_cfg.env.num_envs + i,\n",
    "#             0 * model_cfg.env.num_envs,\n",
    "#             \"./imagination\",\n",
    "#             \"imagination\",\n",
    "#             vector_env_idx=i,\n",
    "#         )\n",
    "#         for i in range(model_cfg.env.num_envs)\n",
    "#     ]\n",
    "# )\n",
    "# action_space = envs.single_action_space\n",
    "# observation_space = envs.single_observation_space\n",
    "\n",
    "# obs_keys = model_cfg.algo.cnn_keys.encoder + model_cfg.algo.mlp_keys.encoder\n",
    "# is_continuous = isinstance(action_space, gym.spaces.Box)\n",
    "# is_multidiscrete = isinstance(action_space, gym.spaces.MultiDiscrete)\n",
    "# actions_dim = tuple(\n",
    "#     action_space.shape if is_continuous else (action_space.nvec.tolist() if is_multidiscrete else [action_space.n])\n",
    "# )\n",
    "# is_continuous = isinstance(action_space, gym.spaces.Box)\n",
    "# is_multidiscrete = isinstance(action_space, gym.spaces.MultiDiscrete)\n",
    "# actions_dim = tuple(\n",
    "#     action_space.shape if is_continuous else (action_space.nvec.tolist() if is_multidiscrete else [action_space.n])\n",
    "# )\n",
    "world_model, actor, critic, critic_target, player = build_agent(\n",
    "    fabric,\n",
    "    actions_dim,\n",
    "    is_continuous,\n",
    "    cfg,\n",
    "    observation_space,\n",
    "    model_state[\"world_model\"],\n",
    "    model_state[\"actor\"],\n",
    "    model_state[\"critic\"],\n",
    "    model_state[\"target_critic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1210001 [00:09<1463:43:54,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.65117645263672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1002/1210001 [22:18<438:01:37,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.34780883789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2002/1210001 [44:20<463:56:13,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.34278106689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3002/1210001 [1:06:19<436:39:54,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.37515258789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4002/1210001 [1:28:20<437:00:49,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.92355346679688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5002/1210001 [1:50:12<434:38:21,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.25057983398438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6002/1210001 [2:12:18<444:04:17,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.67758178710938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7002/1210001 [2:34:29<438:11:50,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.06826782226562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8002/1210001 [2:56:34<468:33:40,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.1716537475586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9002/1210001 [3:19:09<434:41:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.94760131835938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10002/1210001 [3:42:12<491:57:53,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.81026458740234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10130/1210001 [3:45:06<444:23:25,  1.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m     priors_logits[i] \u001b[38;5;241m=\u001b[39m prior_logits\n\u001b[0;32m     50\u001b[0m     posteriors[i] \u001b[38;5;241m=\u001b[39m posterior\n\u001b[1;32m---> 51\u001b[0m     posteriors_logits[i] \u001b[38;5;241m=\u001b[39m posterior_logits\n\u001b[0;32m     52\u001b[0m latent_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((posteriors\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mposteriors\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), recurrent_states), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     54\u001b[0m ensemble_optimizer \u001b[38;5;241m=\u001b[39m hydra\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39minstantiate(\n\u001b[0;32m     55\u001b[0m     cfg\u001b[38;5;241m.\u001b[39malgo\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer, params\u001b[38;5;241m=\u001b[39mensembles\u001b[38;5;241m.\u001b[39mparameters(), _convert_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_steps_per_iter = int(cfg.env.num_envs * fabric.world_size)\n",
    "total_iters = int(cfg.algo.total_steps // policy_steps_per_iter) if not cfg.dry_run else 1\n",
    "\n",
    "for iter_num in tqdm(range(39999, total_iters)):\n",
    "\n",
    "    local_data = rb.sample_tensors(\n",
    "        cfg.algo.per_rank_batch_size,\n",
    "        sequence_length=cfg.algo.per_rank_sequence_length,\n",
    "        n_samples=64,\n",
    "        dtype=None,\n",
    "        device=fabric.device,\n",
    "        from_numpy=cfg.buffer.from_numpy,\n",
    "    )\n",
    "    batch = {k: v[i].float() for k, v in local_data.items()}\n",
    "    data = batch\n",
    "\n",
    "    batch_size = cfg.algo.per_rank_batch_size\n",
    "    sequence_length = cfg.algo.per_rank_sequence_length\n",
    "    recurrent_state_size = cfg.algo.world_model.recurrent_model.recurrent_state_size\n",
    "    stochastic_size = cfg.algo.world_model.stochastic_size\n",
    "    discrete_size = cfg.algo.world_model.discrete_size\n",
    "    device = fabric.device\n",
    "    data = {k: data[k] for k in data.keys()}\n",
    "    batch_obs = {k: data[k] / 255.0 - 0.5 for k in cfg.algo.cnn_keys.encoder}\n",
    "    batch_obs.update({k: data[k] for k in cfg.algo.mlp_keys.encoder})\n",
    "    data[\"is_first\"][0, :] = torch.ones_like(data[\"is_first\"][0, :])\n",
    "\n",
    "    # Given how the environment interaction works, we remove the last actions\n",
    "    # and add the first one as the zero action\n",
    "    batch_actions = torch.cat((torch.zeros_like(data[\"actions\"][:1]), data[\"actions\"][:-1]), dim=0)\n",
    "\n",
    "    # Dynamic Learning\n",
    "    stoch_state_size = stochastic_size * discrete_size\n",
    "    recurrent_state = torch.zeros(1, batch_size, recurrent_state_size, device=device)\n",
    "    posterior = torch.zeros(1, batch_size, stochastic_size, discrete_size, device=device)\n",
    "    recurrent_states = torch.empty(sequence_length, batch_size, recurrent_state_size, device=device)\n",
    "    priors_logits = torch.empty(sequence_length, batch_size, stoch_state_size, device=device)\n",
    "    posteriors = torch.empty(sequence_length, batch_size, stochastic_size, discrete_size, device=device)\n",
    "    posteriors_logits = torch.empty(sequence_length, batch_size, stoch_state_size, device=device)\n",
    "\n",
    "    # embedded observations from the environment\n",
    "    embedded_obs = world_model.encoder(batch_obs)\n",
    "\n",
    "    for i in range(0, sequence_length):\n",
    "        recurrent_state, posterior, _, posterior_logits, prior_logits = world_model.rssm.dynamic(\n",
    "            posterior, recurrent_state, batch_actions[i : i + 1], embedded_obs[i : i + 1], data[\"is_first\"][i : i + 1]\n",
    "        )\n",
    "        recurrent_states[i] = recurrent_state\n",
    "        priors_logits[i] = prior_logits\n",
    "        posteriors[i] = posterior\n",
    "        posteriors_logits[i] = posterior_logits\n",
    "    latent_states = torch.cat((posteriors.view(*posteriors.shape[:-2], -1), recurrent_states), -1)\n",
    "\n",
    "    ensemble_optimizer = hydra.utils.instantiate(\n",
    "        cfg.algo.critic.optimizer, params=ensembles.parameters(), _convert_=\"all\"\n",
    "    )\n",
    "\n",
    "    loss = 0.0\n",
    "    ensemble_optimizer.zero_grad(set_to_none=True)\n",
    "    for ens in ensembles:\n",
    "        out = ens(\n",
    "            torch.cat(\n",
    "                (\n",
    "                    posteriors.view(*posteriors.shape[:-2], -1).detach(),\n",
    "                    recurrent_states.detach(),\n",
    "                    data[\"actions\"].detach(),\n",
    "                ),\n",
    "                -1,\n",
    "            )\n",
    "        )[:-1]\n",
    "        next_state_embedding_dist = MSEDistribution(out, 1)\n",
    "        loss -= next_state_embedding_dist.log_prob(posteriors.view(sequence_length, batch_size, -1).detach()[1:]).mean()\n",
    "    loss.backward()\n",
    "\n",
    "    #print(loss.item())\n",
    "    if iter_num % 1000 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "    ensemble_grad = None\n",
    "    if cfg.algo.ensembles.clip_gradients is not None and cfg.algo.ensembles.clip_gradients > 0:\n",
    "        ensemble_grad = fabric.clip_gradients(\n",
    "            module=ens,\n",
    "            optimizer=ensemble_optimizer,\n",
    "            max_norm=cfg.algo.ensembles.clip_gradients,\n",
    "            error_if_nonfinite=False,\n",
    "        )\n",
    "    ensemble_optimizer.step()\n",
    "\n",
    "    if (iter_num+1) % 10000 == 0:\n",
    "        state = {\n",
    "            \"ensembles\": ensembles.state_dict(),\n",
    "            \"ensemble_optimizer\": ensemble_optimizer.state_dict(),\n",
    "            \"iter_num\": iter_num * world_size,\n",
    "            \"batch_size\": cfg.algo.per_rank_batch_size * world_size,\n",
    "        }\n",
    "        ckpt_path = fr\"C:\\Users\\user\\Documents\\MasterThesis\\sheep RL\\sheeprl-main\\notebooks\\checkpoints_ensembles\\ckpt_{iter_num}_{fabric.global_rank}.ckpt\"\n",
    "        fabric.save(ckpt_path, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006449965294450521\n",
      "0.00018769799498841166\n",
      "0.0002079825644614175\n",
      "0.0003028228529728949\n",
      "0.0003159301704727113\n",
      "0.0002625550841912627\n",
      "0.00023666485503781587\n",
      "0.00021871173521503806\n",
      "0.0002210103120887652\n",
      "0.00022103193623479456\n",
      "0.00021067471243441105\n",
      "0.00022386792988982052\n",
      "0.00020755603327415884\n",
      "0.00028745405143126845\n",
      "0.00022042490309104323\n",
      "0.00021592702250927687\n",
      "0.00042325197136960924\n",
      "0.00035299500450491905\n",
      "0.00033605776843614876\n",
      "0.00017703816411085427\n",
      "0.00020869733998551965\n",
      "0.00019944040104746819\n",
      "0.00017044864944182336\n",
      "0.00015068605716805905\n",
      "0.00017090157780330628\n",
      "0.00014473972260020673\n",
      "0.0001942969101946801\n",
      "0.0003904083860106766\n",
      "0.0002764298114925623\n",
      "0.00022933899890631437\n",
      "0.00016008209786377847\n",
      "0.0001863927027443424\n",
      "0.00023655610857531428\n",
      "0.00034613063326105475\n",
      "0.000315347861032933\n",
      "0.0003102956688962877\n",
      "0.000256091560004279\n",
      "0.0003233199822716415\n",
      "0.00027932034572586417\n",
      "0.00023034510377328843\n",
      "0.0001903433003462851\n",
      "0.00023273623082786798\n",
      "0.00019829437951557338\n",
      "0.0002154249232262373\n",
      "0.0002665084903128445\n",
      "0.00023571695783175528\n",
      "0.00020268023945391178\n",
      "0.00017316610319539905\n",
      "0.000178549496922642\n",
      "0.00017621676670387387\n",
      "0.00023955560754984617\n",
      "0.00023942097323015332\n",
      "0.000275689730187878\n",
      "0.0003448780917096883\n",
      "0.00037765997694805264\n",
      "0.00035421078791841865\n",
      "0.00026114878710359335\n",
      "0.000222586008021608\n",
      "0.0002031102922046557\n",
      "0.000222979171667248\n",
      "0.00021860421111341566\n",
      "0.00018858572002500296\n",
      "0.00022398335568141192\n",
      "0.00023718233569525182\n",
      "0.0002481313422322273\n",
      "0.00023787154350429773\n",
      "0.0002104339364450425\n",
      "0.0002254719438496977\n",
      "0.00023570915800519288\n",
      "0.00021166203077882528\n",
      "0.00024067453341558576\n",
      "0.0002212422259617597\n",
      "0.00026208499912172556\n",
      "0.00029117357917129993\n",
      "0.00029299009474925697\n",
      "0.00024621281772851944\n",
      "0.00023334386060014367\n",
      "0.00024909822968766093\n",
      "0.0002552951336838305\n",
      "0.00027437767130322754\n",
      "0.00026299658929929137\n",
      "0.00024080877483356744\n",
      "0.00029525355785153806\n",
      "0.00025633678887970746\n",
      "0.0002328544796910137\n",
      "0.0003063197946175933\n",
      "0.000247972144279629\n",
      "0.00025271603954024613\n",
      "0.00026259123114869\n",
      "0.00032163900323212147\n",
      "0.000249413657002151\n",
      "0.00024376946385018528\n",
      "0.00027395389042794704\n",
      "0.0002889470779336989\n",
      "0.0002628887305036187\n",
      "0.0002728659310378134\n",
      "0.00024758692597970366\n",
      "0.0002956631942652166\n",
      "0.00024473227676935494\n",
      "0.0002959542325697839\n",
      "0.00026721463655121624\n",
      "0.00023995383526198566\n",
      "0.0002695046423468739\n",
      "0.00026497896760702133\n",
      "0.00023191973741631955\n",
      "0.000274444289971143\n",
      "0.00023470266023650765\n",
      "0.0002489695034455508\n",
      "0.0002895710349548608\n",
      "0.00025953067233785987\n",
      "0.0003031016676686704\n",
      "0.00024858376127667725\n",
      "0.00023678627621848136\n",
      "0.00025730839115567505\n",
      "0.0002847823197953403\n",
      "0.00023699799203313887\n",
      "0.00022888206876814365\n",
      "0.00021552102407440543\n",
      "0.0003492218966130167\n",
      "0.0003454101679380983\n",
      "0.0002710509579628706\n",
      "0.0002729239931795746\n",
      "0.00018644164083525538\n",
      "0.0002100062556564808\n",
      "0.0002566960174590349\n",
      "0.0002826887648552656\n",
      "0.0003519491001497954\n",
      "0.00035839714109897614\n",
      "0.0003597661852836609\n",
      "0.00031497125746682286\n",
      "0.00024508131900802255\n",
      "0.00021024735178798437\n",
      "0.00024503370514139533\n",
      "0.0002145016915164888\n",
      "0.00020734329882543534\n",
      "0.00022554850147571415\n",
      "0.000219860696233809\n",
      "0.0001804467901820317\n",
      "0.00022846844512969255\n",
      "0.00020959810353815556\n",
      "0.00021004251902922988\n",
      "0.00022647346486337483\n",
      "0.00028895362629555166\n",
      "0.000259587075561285\n",
      "0.0002985754399560392\n",
      "0.000281229498796165\n",
      "0.0002454761415719986\n",
      "0.0002408125437796116\n",
      "0.00027786873397417367\n",
      "0.0002757385082077235\n",
      "0.0002634310512803495\n",
      "0.00022923381766304374\n",
      "0.0002224641211796552\n",
      "0.00022534996969625354\n",
      "0.0002509001351427287\n",
      "0.00024528143694624305\n",
      "0.0002230413956567645\n",
      "0.0002401631500106305\n",
      "0.0002686309744603932\n",
      "0.00030061343568377197\n",
      "0.00025260713300667703\n",
      "0.0003372441278770566\n",
      "0.0003236968768760562\n",
      "0.0002964209415949881\n",
      "0.00028658966766670346\n",
      "0.0003172607102897018\n",
      "0.0002896132646128535\n",
      "0.00023756176233291626\n",
      "0.0002461096446495503\n",
      "0.0002680551551748067\n",
      "0.0002652807452250272\n",
      "0.00022528220142703503\n",
      "0.00024285580730065703\n",
      "0.00021685604588128626\n",
      "0.0002413598558632657\n",
      "0.00029745110077783465\n",
      "0.00028051817207597196\n",
      "0.0003109698591288179\n",
      "0.00025201356038451195\n",
      "0.00029047386487945914\n",
      "0.0002747634134721011\n",
      "0.00026590886409394443\n",
      "0.0002499227412045002\n",
      "0.0002337808400625363\n",
      "0.00024091184604912996\n",
      "0.000268146104644984\n",
      "0.0002597238344606012\n",
      "0.00023641742882318795\n",
      "0.00027406573644839227\n",
      "0.00028323876904323697\n",
      "0.00030621810583397746\n",
      "0.0002591002266854048\n",
      "0.0002754130109678954\n",
      "0.0002850508317351341\n",
      "0.00029438038473017514\n",
      "0.00029582728166133165\n",
      "0.00033866011654026806\n",
      "0.00026564946165308356\n",
      "0.0002546848845668137\n",
      "0.00030849536415189505\n",
      "0.00022532936418429017\n",
      "0.00026491296011954546\n",
      "0.00026137629174627364\n",
      "0.00028365550679154694\n",
      "0.0002555344544816762\n",
      "0.00026394741144031286\n",
      "0.00023510438040830195\n",
      "0.0002532866201363504\n",
      "0.0002197349676862359\n",
      "0.00026743224589154124\n",
      "0.00028061523335054517\n",
      "0.0002863524714484811\n",
      "0.00021518307039514184\n",
      "0.0002572829253040254\n",
      "0.00025496550370007753\n",
      "0.00032558507518842816\n",
      "0.0002596135309431702\n",
      "0.00028720387490466237\n",
      "0.00027585349744185805\n",
      "0.0003087617224082351\n",
      "0.0002780411159619689\n",
      "0.0002830673474818468\n",
      "0.00031965028028935194\n",
      "0.0003348032187204808\n",
      "0.0003101725014857948\n",
      "0.0002992427907884121\n",
      "0.0002814507170114666\n",
      "0.0003043278702534735\n",
      "0.00024964718613773584\n",
      "0.00029557899688370526\n",
      "0.00024710712023079395\n",
      "0.00026254807016812265\n",
      "0.00023555746884085238\n",
      "0.00022503474610857666\n",
      "0.00023952568881213665\n",
      "0.000221421621972695\n",
      "0.0002503570867702365\n",
      "0.0002337981277378276\n",
      "0.0002741423377301544\n",
      "0.00025803392054513097\n",
      "0.0002567026822362095\n",
      "0.0003174985176883638\n",
      "0.00024149598903022707\n",
      "0.00026128150057047606\n",
      "0.0002915644145105034\n",
      "0.0002796307089738548\n",
      "0.00025545130483806133\n",
      "0.00023493483604397625\n",
      "0.00024906310136429965\n",
      "0.00024025386665016413\n",
      "0.0002474288921803236\n",
      "0.00024898932315409184\n",
      "0.00025148061104118824\n",
      "0.00023133226204663515\n",
      "0.00029888126300647855\n",
      "0.00024520480656065047\n",
      "0.00028468179516494274\n",
      "0.00028540004859678447\n",
      "0.0002348166744923219\n",
      "0.00025298711261712015\n",
      "0.0002541039721108973\n",
      "0.0002752040745690465\n",
      "0.00024987809592857957\n",
      "0.0003111035912297666\n",
      "0.00024483565357513726\n",
      "0.00024453410878777504\n",
      "0.0002791190054267645\n",
      "0.0002597748243715614\n",
      "0.00029554596403613687\n",
      "0.00025946134701371193\n",
      "0.0002875635400414467\n",
      "0.0002818227221723646\n",
      "0.000299702282063663\n",
      "0.00028929332620464265\n",
      "0.0002605338813737035\n",
      "0.0002142246812582016\n",
      "0.00022878828167449683\n",
      "0.00025191024178639054\n",
      "0.00031521229539066553\n",
      "0.0002842848771251738\n",
      "0.00026507576694712043\n",
      "0.0002982197911478579\n",
      "0.000263170717516914\n",
      "0.0002512353239580989\n",
      "0.00025043764617294073\n",
      "0.00023122246784623712\n",
      "0.0002859103842638433\n",
      "0.00028230599127709866\n",
      "0.0002933400101028383\n",
      "0.00032248583738692105\n",
      "0.00029727068613283336\n",
      "0.00029030622681602836\n",
      "0.00039123790338635445\n",
      "0.00029360828921198845\n",
      "0.0002853181795217097\n",
      "0.00027350979507900774\n",
      "0.0002587505732662976\n",
      "0.00022407059441320598\n",
      "0.0002201643364969641\n",
      "0.0002319560298928991\n",
      "0.0002411359891993925\n",
      "0.0002435805945424363\n",
      "0.00022071073180995882\n",
      "0.0002075368829537183\n",
      "0.0003266196290496737\n",
      "0.00030996985151432455\n",
      "0.00025404596817679703\n",
      "0.0002530080091673881\n",
      "0.00019577177590690553\n",
      "0.00021262041991576552\n",
      "0.000198411347810179\n",
      "0.0002823674294631928\n",
      "0.00025841715978458524\n",
      "0.0002730390406213701\n",
      "0.0004135852213948965\n",
      "0.0002451367909088731\n",
      "0.00023885673726908863\n",
      "0.00022959102352615446\n",
      "0.00019494093430694193\n",
      "0.00022073864238336682\n",
      "0.0001994079357245937\n",
      "0.00019859927124343812\n",
      "0.000213797262404114\n",
      "0.0001966872368939221\n",
      "0.0002008708834182471\n",
      "0.0001954948966158554\n",
      "0.00017425605619791895\n",
      "0.00017347867833450437\n",
      "0.0002140349242836237\n",
      "0.0002036063524428755\n",
      "0.00022558218915946782\n",
      "0.00022199563682079315\n",
      "0.00030454667285084724\n",
      "0.0003459751314949244\n",
      "0.0002354546304559335\n",
      "0.00020928308367729187\n",
      "0.00022702128626406193\n",
      "0.00022374896798282862\n",
      "0.00019553527818061411\n",
      "0.00020225514890626073\n",
      "0.00019643057021312416\n",
      "0.00019595485355239362\n",
      "0.00020403999951668084\n",
      "0.00024287165433634073\n",
      "0.00027688773116096854\n",
      "0.00023796105233486742\n",
      "0.00024065340403467417\n",
      "0.0002389938017586246\n",
      "0.00022205646382644773\n",
      "0.0002983933372888714\n",
      "0.0002243306953459978\n",
      "0.00023793120635673404\n",
      "0.000206413387786597\n",
      "0.00020558701362460852\n",
      "0.00022554682800546288\n",
      "0.0002414293121546507\n",
      "0.0002600732259452343\n",
      "0.000245483941398561\n",
      "0.00023385492386296391\n",
      "0.00027216679882258177\n",
      "0.00024369443417526782\n",
      "0.00022119608183857054\n",
      "0.00027669587871059775\n",
      "0.0002538686676416546\n",
      "0.00022830648231320083\n",
      "0.0002701192570384592\n",
      "0.0002804555115289986\n",
      "0.00031559454509988427\n",
      "0.0002643010811880231\n",
      "0.000262366869719699\n",
      "0.00025237121735699475\n",
      "0.0002610998344607651\n",
      "0.0002572227967903018\n",
      "0.0002857970248442143\n",
      "0.00026074182824231684\n",
      "0.00024895055685192347\n",
      "0.00024588368250988424\n",
      "0.0002469844766892493\n",
      "0.0002553559606894851\n",
      "0.00028199079679325223\n",
      "0.0002500280679669231\n",
      "0.00025614348123781383\n",
      "0.000294662662781775\n",
      "0.0002815612533595413\n",
      "0.0002744969679042697\n",
      "0.0002467762096785009\n",
      "0.0002804996620398015\n",
      "0.00027598137967288494\n",
      "0.00029465858824551105\n",
      "0.0002426264836685732\n",
      "0.0002576471888460219\n",
      "0.00022751238429918885\n",
      "0.00022115577303338796\n",
      "0.00024517421843484044\n",
      "0.00023661149316467345\n",
      "0.0002766708785202354\n",
      "0.0002431799512123689\n",
      "0.0002771747822407633\n",
      "0.00025961126084439456\n",
      "0.0003037388378288597\n",
      "0.0002758364425972104\n",
      "0.0002531093778088689\n",
      "0.00024702365044504404\n",
      "0.00021582157933153212\n",
      "0.00023044338740874082\n",
      "0.0002353937306907028\n",
      "0.00023940083337947726\n",
      "0.0002374826290179044\n",
      "0.00023282459005713463\n",
      "0.0002428076695650816\n",
      "0.000279511819826439\n",
      "0.00028915543225593865\n",
      "0.00027457537362352014\n",
      "0.00023876405612099916\n",
      "0.00025330117205157876\n",
      "0.0002529442426748574\n",
      "0.00023954740026965737\n",
      "0.0002408611326245591\n",
      "0.00025622639805078506\n",
      "0.00023676278942730278\n",
      "0.0002551190264057368\n",
      "0.00022201446699909866\n",
      "0.00022118244669400156\n",
      "0.0002155490219593048\n",
      "0.00020721755572594702\n",
      "0.00020899611990898848\n",
      "0.00022070537670515478\n",
      "0.0003455952974036336\n",
      "0.00027756436611525714\n",
      "0.00025423825718462467\n",
      "0.00019746285397559404\n",
      "0.00021118219592608511\n",
      "0.0002171155356336385\n",
      "0.0002563639427535236\n",
      "0.00023735806462354958\n",
      "0.0002500960836187005\n",
      "0.0003150512930005789\n",
      "0.00033274877932853997\n",
      "0.00025335513055324554\n",
      "0.00023820638307370245\n",
      "0.00021797789668198675\n",
      "0.0002573274541646242\n",
      "0.0002561595174483955\n",
      "0.0002556170802563429\n",
      "0.0002503835712559521\n",
      "0.00026734801940619946\n",
      "0.0002150941436411813\n",
      "0.00021918451238889247\n",
      "0.00019274484657216817\n",
      "0.0002049717295449227\n",
      "0.00021851790370419621\n",
      "0.00021834979997947812\n",
      "0.00024281704099848866\n",
      "0.0002728886902332306\n",
      "0.0002441585238557309\n",
      "0.0001962150854524225\n",
      "0.00022662634728476405\n",
      "0.00023069328744895756\n",
      "0.00022024505597073585\n",
      "0.0002177196292905137\n",
      "0.0002034455246757716\n",
      "0.00020605549798347056\n",
      "0.00023490554303862154\n",
      "0.0002549696946516633\n",
      "0.0002479315153323114\n",
      "0.00029246884514577687\n",
      "0.00024701913935132325\n",
      "0.00028237837250344455\n",
      "0.0002932811912614852\n",
      "0.0002671259280759841\n",
      "0.00025392769020982087\n",
      "0.0002631150418892503\n",
      "0.0002867631264962256\n",
      "0.0002564461901783943\n",
      "0.0002653528063092381\n",
      "0.00023137882817536592\n",
      "0.00023341013002209365\n",
      "0.00022324224119074643\n",
      "0.0002296004386153072\n",
      "0.00022007545339874923\n",
      "0.00026794985751621425\n",
      "0.0002622330212034285\n",
      "0.0002303319051861763\n",
      "0.00025610512238927186\n",
      "0.0003009439678862691\n",
      "0.0002487684541847557\n",
      "0.00026217399863526225\n",
      "0.00023505708668380976\n",
      "0.00029639009153470397\n",
      "0.0002799519570544362\n",
      "0.0002762489311862737\n",
      "0.00028063214267604053\n",
      "0.00029148225439712405\n",
      "0.00028280384140089154\n",
      "0.0002936725795734674\n",
      "0.00028459742316044867\n",
      "0.00022129995340947062\n",
      "0.0002898135280702263\n",
      "0.00028198183281347156\n",
      "0.00026382014038972557\n",
      "0.00024771736934781075\n",
      "0.0002900695544667542\n",
      "0.0002841131645254791\n",
      "0.00027170678367838264\n",
      "0.00025867525255307555\n",
      "0.0003017859417013824\n",
      "0.00026033842004835606\n",
      "0.00030968248029239476\n",
      "0.00024089742510113865\n",
      "0.00023088209854904562\n",
      "0.00023749552201479673\n",
      "0.00026144145522266626\n",
      "0.0002715113223530352\n",
      "0.000264022673945874\n",
      "0.0002453595807310194\n",
      "0.0002552528749220073\n",
      "0.00027370970929041505\n",
      "0.00024029890482779592\n",
      "0.000295084435492754\n",
      "0.0002652700350154191\n",
      "0.0002837818465195596\n",
      "0.00023177657567430288\n",
      "0.00023649819195270538\n",
      "0.00021209759870544076\n",
      "0.00024507608031854033\n",
      "0.00021704105893149972\n",
      "0.00021440121054183692\n",
      "0.00023777634487487376\n",
      "0.00025280745467171073\n",
      "0.0003275380877312273\n",
      "0.000304881832562387\n",
      "0.0002203207986894995\n",
      "0.0002120697172358632\n",
      "0.00019728505867533386\n",
      "0.0002433867921354249\n",
      "0.0003060939779970795\n",
      "0.0002771220460999757\n",
      "0.00030347867868840694\n",
      "0.0003086087526753545\n",
      "0.0003691667807288468\n",
      "0.0002618820872157812\n",
      "0.0002132423542207107\n",
      "0.00018931421800516546\n",
      "0.00020850624423474073\n",
      "0.00020854963804595172\n",
      "0.00019600929226726294\n",
      "0.00018195515440311283\n",
      "0.00018429233750794083\n",
      "0.00018013337103184313\n",
      "0.0002121497964253649\n",
      "0.00019787836936302483\n",
      "0.00021476662368513644\n",
      "0.00024805113207548857\n",
      "0.00029274349799379706\n",
      "0.00023812989820726216\n",
      "0.0002275475999340415\n",
      "0.00022004023776389658\n",
      "0.00021849946642760187\n",
      "0.00020990091434214264\n",
      "0.00018288465798832476\n",
      "0.00019560598593670875\n",
      "0.00023649807553738356\n",
      "0.00021552445832639933\n",
      "0.0002650036185514182\n",
      "0.0003354602085892111\n",
      "0.0002623825566843152\n",
      "0.00026325060753151774\n",
      "0.00023228139616549015\n",
      "0.00024362026306334883\n",
      "0.00025802728487178683\n",
      "0.0002529300982132554\n",
      "0.00023840824724175036\n",
      "0.00020661542657762766\n",
      "0.0002553087251726538\n",
      "0.00025727349566295743\n",
      "0.0002492332714609802\n",
      "0.00025407271459698677\n",
      "0.00023847610282246023\n",
      "0.00022949333651922643\n",
      "0.00024299972574226558\n",
      "0.00026288541266694665\n",
      "0.0003083079936914146\n",
      "0.0002783903037197888\n",
      "0.00029021615046076477\n",
      "0.00028590840520337224\n",
      "0.000304326880723238\n",
      "0.00025065563386306167\n",
      "0.0002768610720522702\n",
      "0.0002303734072484076\n",
      "0.00021678541088476777\n",
      "0.0002491394116077572\n",
      "0.0002410117449471727\n",
      "0.0002577036211732775\n",
      "0.0002239457971882075\n",
      "0.000228527671424672\n",
      "0.0002758951159194112\n",
      "0.000222165253944695\n",
      "0.00026844130479730666\n",
      "0.00027456716634333134\n",
      "0.00022571177396457642\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "import copy\n",
    "import pathlib\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from lightning.fabric import Fabric\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "from sheeprl.algos.dreamer_v3.agent import build_agent\n",
    "#from sheeprl.algos.p2e_dv3.agent import build_agent\n",
    "from sheeprl.data.buffers import SequentialReplayBuffer\n",
    "from sheeprl.utils.env import make_env\n",
    "from sheeprl.utils.utils import dotdict\n",
    "## Agent and Environment initialization\n",
    "\n",
    "# path of your checkpoint\n",
    "ckpt_path = pathlib.Path(r\"C:\\Users\\user\\Documents\\MasterThesis\\sheep RL\\sheeprl-main\\logs\\runs\\dreamer_v3\\PongNoFrameskip-v4\\2024-06-17_00-51-22_dreamer_v3_PongNoFrameskip-v4_42\\version_0\\checkpoint\\ckpt_120000_0.ckpt\")\n",
    "seed = 12\n",
    "fabric = Fabric(accelerator=\"cuda\", devices=1)\n",
    "fabric.launch()\n",
    "state = fabric.load(ckpt_path)\n",
    "cfg = dotdict(OmegaConf.to_container(OmegaConf.load(ckpt_path.parent.parent / \"config.yaml\"), resolve=True))\n",
    "\n",
    "#fabric.seed_everything(cfg.seed)\n",
    "# The number of environments is set to 1\n",
    "cfg.env.num_envs = 1\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [\n",
    "        make_env(\n",
    "            cfg,\n",
    "            cfg.seed + 0 * cfg.env.num_envs + i,\n",
    "            0 * cfg.env.num_envs,\n",
    "            \"./imagination\",\n",
    "            \"imagination\",\n",
    "            vector_env_idx=i,\n",
    "        )\n",
    "        for i in range(cfg.env.num_envs)\n",
    "    ]\n",
    ")\n",
    "action_space = envs.single_action_space\n",
    "observation_space = envs.single_observation_space\n",
    "\n",
    "obs_keys = cfg.algo.cnn_keys.encoder + cfg.algo.mlp_keys.encoder\n",
    "# is_continuous = isinstance(action_space, gym.spaces.Box)\n",
    "# is_multidiscrete = isinstance(action_space, gym.spaces.MultiDiscrete)\n",
    "# actions_dim = tuple(\n",
    "#     action_space.shape if is_continuous else (action_space.nvec.tolist() if is_multidiscrete else [action_space.n])\n",
    "# )\n",
    "# (\n",
    "#     world_model,\n",
    "#     ensembles,\n",
    "#     actor,\n",
    "#     critic,\n",
    "#     target_critic,\n",
    "#     actor_exploration,\n",
    "#     critics_exploration,\n",
    "#     player,\n",
    "# ) = build_agent(\n",
    "#     fabric,\n",
    "#     actions_dim,\n",
    "#     is_continuous,\n",
    "#     cfg,\n",
    "#     observation_space,\n",
    "#     state[\"world_model\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"ensembles\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"actor_task\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"critic_task\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"target_critic_task\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"actor_exploration\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"critics_exploration\"] if cfg.checkpoint.resume_from else None,\n",
    "# )\n",
    "# is_continuous = isinstance(action_space, gym.spaces.Box)\n",
    "# is_multidiscrete = isinstance(action_space, gym.spaces.MultiDiscrete)\n",
    "# actions_dim = tuple(\n",
    "#     action_space.shape if is_continuous else (action_space.nvec.tolist() if is_multidiscrete else [action_space.n])\n",
    "# )\n",
    "# (\n",
    "#     world_model_f,\n",
    "#     ensembles_f,\n",
    "#     actor_f,\n",
    "#     critic_f,\n",
    "#     target_critic_f,\n",
    "#     actor_exploration_f,\n",
    "#     critics_exploration_f,\n",
    "#     player_f,\n",
    "# ) = build_agent(\n",
    "#     fabric,\n",
    "#     actions_dim,\n",
    "#     is_continuous,\n",
    "#     cfg,\n",
    "#     observation_space,\n",
    "#     state[\"world_model\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"ensembles\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"actor_task\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"critic_task\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"target_critic_task\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"actor_exploration\"] if cfg.checkpoint.resume_from else None,\n",
    "#     state[\"critics_exploration\"] if cfg.checkpoint.resume_from else None,\n",
    "# )\n",
    "is_continuous = isinstance(action_space, gym.spaces.Box)\n",
    "is_multidiscrete = isinstance(action_space, gym.spaces.MultiDiscrete)\n",
    "actions_dim = tuple(\n",
    "    action_space.shape if is_continuous else (action_space.nvec.tolist() if is_multidiscrete else [action_space.n])\n",
    ")\n",
    "world_model, actor, critic, critic_target, player = build_agent(\n",
    "    fabric,\n",
    "    actions_dim,\n",
    "    is_continuous,\n",
    "    cfg,\n",
    "    observation_space,\n",
    "    state[\"world_model\"],\n",
    "    state[\"actor\"],\n",
    "    state[\"critic\"],\n",
    "    state[\"target_critic\"]\n",
    ")\n",
    "## Buffer initialization\n",
    "\n",
    "\n",
    "initial_steps = 600  # set according to your environment.\n",
    "imagination_steps = 50  # number of imagination steps, must be lower than or equal to the `initial_steps`.\n",
    "clip_rewards_fn = lambda r: torch.tanh(r) if cfg.env.clip_rewards else r\n",
    "rb_initial = SequentialReplayBuffer(initial_steps, cfg.env.num_envs)\n",
    "rb_play = SequentialReplayBuffer(imagination_steps, cfg.env.num_envs)\n",
    "rb_imagination = SequentialReplayBuffer(imagination_steps, cfg.env.num_envs)\n",
    "step_data = {}\n",
    "player.init_states()\n",
    "obs = envs.reset(seed=cfg.seed)[0]\n",
    "for k in obs_keys:\n",
    "    step_data[k] = obs[k][np.newaxis]\n",
    "step_data[\"dones\"] = np.zeros((1, cfg.env.num_envs, 1))\n",
    "step_data[\"rewards\"] = np.zeros((1, cfg.env.num_envs, 1))\n",
    "step_data[\"is_first\"] = np.ones_like(step_data[\"dones\"])\n",
    "## Environment interaction\n",
    "\n",
    "def add_salt_and_pepper_noise(image, salt_prob, pepper_prob):\n",
    "    noisy_image = image.copy()\n",
    "    total_pixels = image.size\n",
    "    num_salt = np.ceil(salt_prob * total_pixels)\n",
    "    num_pepper = np.ceil(pepper_prob * total_pixels)\n",
    "\n",
    "    # Adding salt noise (white pixels)\n",
    "    coords = [np.random.randint(0, i, int(num_salt)) for i in image.shape]\n",
    "    noisy_image[tuple(coords)] = 255\n",
    "\n",
    "    # Adding pepper noise (black pixels)\n",
    "    coords = [np.random.randint(0, i, int(num_pepper)) for i in image.shape]\n",
    "    noisy_image[tuple(coords)] = 0\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=0.3):\n",
    "    gauss = np.random.normal(mean, std, image.shape, )\n",
    "    noisy_image = image + gauss\n",
    "    #noisy_image = np.clip(noisy_image, 0, 1)  # Ensure values are within [0, 1]\n",
    "    return noisy_image\n",
    "\n",
    "salt_prob = 0.3  # 2% of the pixels will be salt noise\n",
    "pepper_prob = 0.3  # 2% of the pixels will be pepper noise\n",
    "info_list = []\n",
    "\n",
    "avg_ld = 0\n",
    "# play for `initial_steps` steps\n",
    "for i in range(initial_steps):\n",
    "    with torch.no_grad():\n",
    "        preprocessed_obs = {}\n",
    "\n",
    "        obs[\"rgb\"] = add_salt_and_pepper_noise(obs[\"rgb\"], salt_prob, pepper_prob)\n",
    "        #obs[\"rgb\"] = np.ones((1,3,64,64)) * 255\n",
    "        for k, v in obs.items():\n",
    "            preprocessed_obs[k] = torch.as_tensor(v[np.newaxis], dtype=torch.float32, device=fabric.device)\n",
    "            if k in cfg.algo.cnn_keys.encoder:\n",
    "                preprocessed_obs[k] = preprocessed_obs[k] / 255.0 - 0.5\n",
    "        mask = {k: v for k, v in preprocessed_obs.items() if k.startswith(\"mask\")}\n",
    "        if len(mask) == 0:\n",
    "            mask = None\n",
    "        real_actions = actions = player.get_actions(preprocessed_obs, mask=mask)\n",
    "        actions = torch.cat(actions, -1).cpu().numpy()\n",
    "\n",
    "        temp_states = torch.cat((player.stochastic_state, player.recurrent_state), -1).to(\"cuda\")\n",
    "        test_input = torch.cat((temp_states, real_actions[0]), -1)\n",
    "\n",
    "        next_state_predictions = []\n",
    "\n",
    "        #ensembles_input[0][0][0] = 10000.0\n",
    "        for ens in ensembles:\n",
    "            next_state_predictions.append(\n",
    "                ens(\n",
    "                    test_input\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        ld = torch.stack(next_state_predictions).var(0).mean(-1, keepdim=True).to(\"cpu\").detach().item()\n",
    "        print(ld)\n",
    "        avg_ld += ld\n",
    "        if is_continuous:\n",
    "            real_actions = torch.stack(real_actions, dim=-1).cpu().numpy()\n",
    "        else:\n",
    "            real_actions = torch.stack([real_act.argmax(dim=-1) for real_act in real_actions], dim=-1).cpu().numpy()\n",
    "\n",
    "    step_data[\"stochastic_state\"] = player.stochastic_state.detach().cpu().numpy()\n",
    "    step_data[\"recurrent_state\"] = player.recurrent_state.detach().cpu().numpy()\n",
    "    step_data[\"actions\"] = actions.reshape((1, cfg.env.num_envs, -1))\n",
    "    rb_initial.add(step_data, validate_args=cfg.buffer.validate_args)\n",
    "\n",
    "    next_obs, rewards, dones, truncated, infos = envs.step(real_actions.reshape(envs.action_space.shape))\n",
    "    #next_obs[\"rgb\"] = add_salt_and_pepper_noise(next_obs[\"rgb\"], salt_prob, pepper_prob)\n",
    "    \n",
    "    rewards = np.array(rewards).reshape((1, cfg.env.num_envs, -1))\n",
    "    dones = np.logical_or(dones, truncated).astype(np.uint8).reshape((1, cfg.env.num_envs, -1))\n",
    "\n",
    "    step_data[\"is_first\"] = np.zeros_like(step_data[\"dones\"])\n",
    "    if \"restart_on_exception\" in infos:\n",
    "        for i, agent_roe in enumerate(infos[\"restart_on_exception\"]):\n",
    "            if agent_roe and not dones[i]:\n",
    "                last_inserted_idx = (rb_initial.buffer[i]._pos - 1) % rb_initial.buffer[i].buffer_size\n",
    "                rb_initial.buffer[i][\"dones\"][last_inserted_idx] = np.ones_like(\n",
    "                    rb_initial.buffer[i][\"dones\"][last_inserted_idx]\n",
    "                )\n",
    "                rb_initial.buffer[i][\"is_first\"][last_inserted_idx] = np.zeros_like(\n",
    "                    rb_initial.buffer[i][\"is_first\"][last_inserted_idx]\n",
    "                )\n",
    "                step_data[\"is_first\"][i] = np.ones_like(step_data[\"is_first\"][i])\n",
    "\n",
    "    real_next_obs = copy.deepcopy(next_obs)\n",
    "    if \"final_observation\" in infos:\n",
    "        for idx, final_obs in enumerate(infos[\"final_observation\"]):\n",
    "            if final_obs is not None:\n",
    "                for k, v in final_obs.items():\n",
    "                    real_next_obs[k][idx] = v\n",
    "\n",
    "    for k in obs_keys:\n",
    "        step_data[k] = next_obs[k][np.newaxis]\n",
    "\n",
    "    obs = next_obs\n",
    "\n",
    "    rewards = rewards.reshape((1, cfg.env.num_envs, -1))\n",
    "    step_data[\"dones\"] = dones.reshape((1, cfg.env.num_envs, -1))\n",
    "    step_data[\"rewards\"] = clip_rewards_fn(rewards)\n",
    "    step_data[\"rewards\"] = clip_rewards_fn(rewards)\n",
    "    dones_idxes = dones.nonzero()[0].tolist()\n",
    "    reset_envs = len(dones_idxes)\n",
    "    if reset_envs > 0:\n",
    "        reset_data = {}\n",
    "        for k in obs_keys:\n",
    "            reset_data[k] = (real_next_obs[k][dones_idxes])[np.newaxis]\n",
    "        reset_data[\"dones\"] = np.ones((1, reset_envs, 1))\n",
    "        reset_data[\"actions\"] = np.zeros((1, reset_envs, np.sum(actions_dim)))\n",
    "        reset_data[\"rewards\"] = step_data[\"rewards\"][:, dones_idxes]\n",
    "        reset_data[\"is_first\"] = np.zeros_like(reset_data[\"dones\"])\n",
    "        rb_initial.add(reset_data, dones_idxes, validate_args=cfg.buffer.validate_args)\n",
    "\n",
    "        # Reset already inserted step data\n",
    "        step_data[\"rewards\"][:, dones_idxes] = np.zeros_like(reset_data[\"rewards\"])\n",
    "        step_data[\"dones\"][:, dones_idxes] = np.zeros_like(step_data[\"dones\"][:, dones_idxes])\n",
    "        step_data[\"is_first\"][:, dones_idxes] = np.ones_like(step_data[\"is_first\"][:, dones_idxes])\n",
    "        player.init_states(dones_idxes)\n",
    "\n",
    "    ## Save the recurrent and stochastic latent states for the imagination phase\n",
    "    if i == initial_steps - imagination_steps:\n",
    "        stochastic_state = player.stochastic_state.clone()\n",
    "        recurrent_state = player.recurrent_state.clone()\n",
    "## Imagination and Reconstruction\n",
    "\n",
    "# deciede if you want to take the actions from the buffer\n",
    "# (i.e., the actions actually played by the agent)\n",
    "# or imagine them and compare with the actions actually played by the agent\n",
    "imagine_actions = True\n",
    "# imagination / reconstruction obs process\n",
    "imagined_latent_states = torch.cat((stochastic_state, recurrent_state), -1)\n",
    "step_data = {}\n",
    "reconstruced_step_data = {}\n",
    "\n",
    "imagined_trajectories = [imagined_latent_states]\n",
    "imagined_actions = []\n",
    "with torch.no_grad():\n",
    "    for i in range(imagination_steps):\n",
    "        if imagine_actions:\n",
    "            # imagined actions\n",
    "            actions = actor(imagined_latent_states.detach())[0][0]\n",
    "            imagined_actions.append(actions)\n",
    "        else:\n",
    "            # actions actually played by the agent\n",
    "            actions = torch.tensor(\n",
    "                rb_initial[\"actions\"][-imagination_steps + i],\n",
    "                device=fabric.device,\n",
    "                dtype=torch.float32,\n",
    "            )[None]\n",
    "            imagined_actions.append(actions)\n",
    "\n",
    "        # imagination step\n",
    "        stochastic_state, recurrent_state = world_model.rssm.imagination(stochastic_state, recurrent_state, actions)\n",
    "        stochastic_state = stochastic_state.view(1, 1, -1)\n",
    "        # update current state\n",
    "        imagined_latent_states = torch.cat((stochastic_state, recurrent_state), -1)\n",
    "        imagined_trajectories.append(imagined_latent_states)\n",
    "\n",
    "        rec_obs = world_model.observation_model(imagined_latent_states)\n",
    "        step_data[\"rgb\"] = rec_obs[\"rgb\"].unsqueeze(0).detach().cpu().numpy() + 0.5\n",
    "        step_data[\"actions\"] = actions.unsqueeze(0).detach().cpu().numpy()\n",
    "        rb_imagination.add(step_data)\n",
    "\n",
    "        # reconstruct the observations from the latent states used when interacting with the environment\n",
    "        played_latent_states = torch.cat(\n",
    "            (\n",
    "                torch.tensor(rb_initial[\"stochastic_state\"][-imagination_steps + i], device=fabric.device),\n",
    "                torch.tensor(rb_initial[\"recurrent_state\"][-imagination_steps + i], device=fabric.device),\n",
    "            ),\n",
    "            -1,\n",
    "        )\n",
    "        rec_obs_played = world_model.observation_model(played_latent_states)\n",
    "        # The decoder has been trained to reconstruct the observations from the latent states in the range [-0.5, 0.5]\n",
    "        # NOTE: Check how the observations are handled in older versions of SheepRL (before 0.5.5)\n",
    "        # if you need to add 0.5 or not (in latest versions it is done automatically by the decoder in its forward method).\n",
    "        reconstruced_step_data[\"rgb\"] = rec_obs_played[\"rgb\"].unsqueeze(0).detach().cpu().numpy() + 0.5\n",
    "        rb_play.add(reconstruced_step_data)\n",
    "ensembles_input = torch.cat((imagined_trajectories[1], imagined_actions[1]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016893557195241254"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ld/initial_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002545898898097221"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ld/initial_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sheeprl.algos.p2e_dv3.agent import build_agent\n",
    "state_ens = fabric.load(r\"C:\\Users\\user\\Documents\\MasterThesis\\sheep RL\\sheeprl-main\\notebooks\\checkpoints_ensembles\\ckpt_39999_0.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "# ens_list = []\n",
    "# cfg_ensembles = cfg.algo.ensembles\n",
    "# ensembles_ln_cls = hydra.utils.get_class(cfg_ensembles.layer_norm.cls)\n",
    "# with isolate_rng():\n",
    "#     for i in range(4):\n",
    "#         fabric.seed_everything(cfg.seed + i)\n",
    "#         ens_list.append(\n",
    "#             MLP(\n",
    "#                 input_dims=int(\n",
    "#                     sum(actions_dim)\n",
    "#                     + cfg.algo.world_model.recurrent_model.recurrent_state_size\n",
    "#                     + cfg.algo.world_model.stochastic_size * cfg.algo.world_model.discrete_size\n",
    "#                 ),\n",
    "#                 output_dim=cfg.algo.world_model.stochastic_size * cfg.algo.world_model.discrete_size,\n",
    "#                 hidden_sizes=[cfg_ensembles.dense_units] * cfg_ensembles.mlp_layers,\n",
    "#                 activation=hydra.utils.get_class(cfg_ensembles.dense_act),\n",
    "#                 flatten_dim=None,\n",
    "#                 layer_args={\"bias\": ensembles_ln_cls == nn.Identity},\n",
    "#                 norm_layer=ensembles_ln_cls,\n",
    "#                 norm_args={\n",
    "#                     **cfg_ensembles.layer_norm.kw,\n",
    "#                     \"normalized_shape\": cfg_ensembles.dense_units,\n",
    "#                 },\n",
    "#             ).apply(init_weights)\n",
    "#         )\n",
    "ensembles = nn.ModuleList(ens_list)\n",
    "if state_ens[\"ensembles\"]:\n",
    "    ensembles.load_state_dict(state_ens[\"ensembles\"])\n",
    "    print(\"hey\")\n",
    "for i in range(len(ensembles)):\n",
    "    ensembles[i] = fabric.setup_module(ensembles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ensembles', 'ensemble_optimizer', 'iter_num', 'batch_size'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_ens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = obs[\"rgb\"]\n",
    "\n",
    "image = image.squeeze().transpose(1, 2, 0)\n",
    "\n",
    "salt_prob = 0.3  # 2% of the pixels will be salt noise\n",
    "pepper_prob = 0.05\n",
    "image = add_salt_and_pepper_noise(image, salt_prob, pepper_prob)\n",
    "# Since the image might be in the range [0, 1], convert it to [0, 255]\n",
    "#image = (image * 255).astype(np.uint8)\n",
    "\n",
    "# Display the image using OpenCV\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs = {\"rgb\": image.reshape(1,3,64,64)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_obs = {}\n",
    "for k, v in new_obs.items():\n",
    "    preprocessed_obs[k] = torch.as_tensor(v[np.newaxis], dtype=torch.float32, device=fabric.device)\n",
    "    if k in cfg.algo.cnn_keys.encoder:\n",
    "        preprocessed_obs[k] = preprocessed_obs[k] / 255.0 - 0.5\n",
    "mask = {k: v for k, v in preprocessed_obs.items() if k.startswith(\"mask\")}\n",
    "if len(mask) == 0:\n",
    "    mask = None\n",
    "real_actions = actions = player.get_actions(preprocessed_obs, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_noise_rec_state = player.recurrent_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.stochastic_state\n",
    "player.recurrent_state\n",
    "\n",
    "imagined_latent_states = torch.cat((player.stochastic_state, player.recurrent_state), -1).to(\"cuda\")\n",
    "test_input = torch.cat((imagined_latent_states, real_actions[0]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0004]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "# Latent disagreement evaluation\n",
    "\n",
    "    salt_prob = 0.55  # 2% of the pixels will be salt noise\n",
    "    pepper_prob = 0.55  # 2% of the pixels will be pepper noise\n",
    "    # ensembles_input = torch.cat((imagined_trajectories[45], imagined_actions[45]), -1)\n",
    "    #ensembles_input = test_input\n",
    "    # ensembles_input = add_gaussian_noise(\n",
    "    #     ensembles_input.cpu(),\n",
    "    #     mean=0,\n",
    "    #     std=0.000000000005\n",
    "    #     ).to(\"cuda\")\n",
    "\n",
    "\n",
    "    #ensembles_input = torch.Tensor(add_salt_and_pepper_noise(ensembles_input.cpu().numpy(), salt_prob, pepper_prob)).to(\"cuda\")\n",
    "   # ensembles_input = ensembles_input.type(torch.float32)\n",
    "    next_state_predictions = []\n",
    "\n",
    "    #ensembles_input[0][0][0] = 10000.0\n",
    "    for ens in ensembles:\n",
    "        next_state_predictions.append(\n",
    "            ens(\n",
    "                test_input\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    print(torch.stack(next_state_predictions).var(0).mean(-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0291"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.0121, -0.0126, -0.0078,  ..., -0.0403,  0.2224,  0.0054]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[ 0.0007, -0.0040,  0.0119,  ..., -0.0925,  0.1733,  0.0109]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-0.0012, -0.0083, -0.0115,  ..., -0.0630,  0.2246, -0.0140]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[ 0.0042,  0.0216,  0.0047,  ..., -0.0007,  0.2231,  0.0054]]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.9204e-01,\n",
       "        -2.6577e-02,  1.1485e-01, -2.9715e-01,  2.8504e-01,  9.7372e-01,\n",
       "        -1.2104e-01,  9.2868e-02,  3.4227e-01, -1.8017e-01,  3.1242e-01,\n",
       "        -9.2735e-01,  1.4306e-01,  2.5604e-01,  4.7433e-02, -8.8480e-01,\n",
       "        -1.4090e-02, -6.4023e-02, -7.4501e-03, -1.1800e-01, -3.4504e-01,\n",
       "         4.4829e-01, -2.4832e-03, -2.7185e-01, -1.2636e-01, -1.9267e-01,\n",
       "         9.1845e-01, -4.2993e-02, -9.7375e-01,  8.3756e-02, -7.4939e-02,\n",
       "        -2.0845e-01,  7.6471e-01, -1.2103e-01,  9.0938e-02,  1.8896e-01,\n",
       "        -8.5878e-01, -1.4089e-02, -2.2358e-01,  2.5581e-01,  2.2538e-01,\n",
       "        -2.4724e-02, -4.7102e-02,  7.9861e-04,  4.6015e-01, -9.6821e-02,\n",
       "        -1.8601e-02, -1.5448e-01, -2.5438e-01, -9.4050e-01, -2.1943e-01,\n",
       "         2.5067e-02, -9.5802e-01,  2.0036e-01, -4.1682e-02,  2.9059e-02,\n",
       "        -5.4822e-03,  6.2902e-03,  1.2315e-01, -1.8852e-01,  1.1346e-01,\n",
       "         2.9312e-01,  5.1229e-01, -1.7787e-01,  6.7575e-01, -3.0282e-01,\n",
       "         3.9493e-01, -1.0591e-01,  2.5026e-01, -3.5832e-02,  8.2895e-03,\n",
       "         9.2561e-01, -6.7778e-03, -3.5157e-01,  4.1041e-01, -7.2472e-01,\n",
       "         5.6654e-02, -2.5082e-01,  1.6059e-02, -1.8984e-01,  2.0528e-01,\n",
       "         9.5592e-01, -1.4104e-01, -2.6337e-01, -3.8431e-01,  2.7198e-01,\n",
       "        -1.3221e-01, -1.7279e-01, -3.7547e-02, -6.8715e-03, -1.7235e-01,\n",
       "         9.7280e-01,  5.9174e-02,  8.0614e-02,  2.5332e-02,  1.2730e-01,\n",
       "         4.7362e-01,  1.5045e-01,  3.5547e-02,  1.0426e-01, -4.3373e-01,\n",
       "         5.4232e-01,  5.2752e-01, -2.6543e-01, -1.6712e-01,  6.6421e-02,\n",
       "         2.1091e-01,  8.3825e-01,  1.8967e-01,  4.3039e-01,  2.6113e-01,\n",
       "        -8.3042e-01, -2.0810e-01,  3.3039e-01, -7.6808e-01, -1.9572e-01,\n",
       "         2.3591e-01,  3.4613e-03, -1.5882e-01, -4.6325e-01,  1.4673e-01,\n",
       "        -3.5987e-01,  2.2171e-02, -2.2521e-02, -7.8705e-02,  7.3470e-02,\n",
       "        -5.3294e-02, -8.1951e-02, -2.1244e-01, -2.9074e-01, -7.5392e-02,\n",
       "        -1.6877e-02,  1.0529e-01,  6.5327e-02, -2.7038e-01,  4.0678e-01,\n",
       "         5.6042e-01, -7.4676e-02, -2.9964e-03, -3.3213e-02, -9.3569e-01,\n",
       "        -3.1548e-01,  9.7977e-01, -1.1292e-01, -1.9001e-01,  1.2511e-01,\n",
       "         4.8408e-01, -5.1306e-01,  1.6125e-02, -1.1757e-01, -6.5846e-02,\n",
       "        -8.3787e-02, -5.5770e-02, -1.1069e-01, -2.6246e-01, -4.5466e-01,\n",
       "        -1.0099e-01,  1.0444e-01, -2.8755e-02,  5.4598e-02, -4.5911e-01,\n",
       "        -3.8363e-01, -1.7182e-01,  2.1605e-01, -5.6879e-02, -6.7672e-01,\n",
       "         4.5394e-02,  1.4959e-01,  1.9585e-01, -1.7451e-01, -7.0317e-02,\n",
       "        -9.2726e-01,  2.3246e-01, -5.2526e-02,  3.7113e-03, -8.1479e-02,\n",
       "        -9.5042e-02, -2.2460e-01,  1.1031e-01, -4.9556e-02,  1.1126e-02,\n",
       "         6.8457e-03, -3.3398e-01,  3.0850e-01,  9.6108e-01,  1.7909e-01,\n",
       "        -2.0258e-01, -2.9821e-01, -8.4197e-02, -9.8094e-01, -5.8133e-02,\n",
       "         1.1917e-01, -6.2416e-02, -2.6687e-01, -1.4764e-01, -9.2333e-01,\n",
       "        -2.3428e-01, -7.4067e-02, -2.8658e-02,  3.3846e-01, -1.6661e-02,\n",
       "        -2.6875e-02,  4.7523e-02,  1.3071e-02,  2.7851e-02, -2.0996e-01,\n",
       "        -9.2365e-02, -9.0175e-01, -3.2596e-02, -1.5188e-01,  1.4165e-02,\n",
       "        -1.7226e-01,  7.6410e-01, -1.4823e-01, -4.4924e-02, -1.6882e-01,\n",
       "         4.4236e-01,  9.6628e-01, -3.0095e-02,  1.5185e-01,  3.3692e-02,\n",
       "        -1.0490e-01, -4.8589e-02,  2.9006e-01, -5.5825e-01, -4.6482e-02,\n",
       "        -3.1391e-02,  2.9358e-02, -4.2595e-02, -8.5231e-01, -2.0852e-01,\n",
       "         7.3500e-02, -1.0598e-01, -3.5387e-02,  5.2728e-02,  1.8589e-01,\n",
       "         8.3000e-02,  2.6205e-01, -1.6385e-01, -6.2624e-01, -2.2052e-02,\n",
       "         9.9795e-02,  4.4502e-01,  1.6516e-01,  5.0412e-01,  2.5314e-01,\n",
       "        -4.9160e-01,  1.3156e-01,  9.9060e-01, -2.7369e-01, -7.9648e-02,\n",
       "         1.1055e-01,  9.9953e-01, -3.0091e-01,  2.4780e-01, -6.0545e-01,\n",
       "        -2.0655e-02, -4.1250e-01,  2.3255e-02, -8.5317e-01, -6.5530e-02,\n",
       "         1.3671e-02,  6.4789e-02, -9.5788e-01,  2.5796e-01,  9.7802e-01,\n",
       "         3.3683e-01, -9.6350e-01, -1.6985e-01,  1.2586e-01,  1.0089e-01,\n",
       "         9.9788e-01,  6.5357e-01, -9.0676e-01, -3.0057e-01,  1.5086e-01,\n",
       "        -4.0301e-01,  1.4431e-01, -3.3261e-01, -3.5840e-03, -1.4795e-02,\n",
       "        -3.7218e-01,  6.8581e-02, -6.3933e-01, -3.1909e-02,  1.1247e-01,\n",
       "         5.4705e-02, -3.0575e-01, -8.2800e-02, -8.4380e-01, -3.4894e-01,\n",
       "         7.7433e-01,  3.1056e-01,  1.4601e-01,  2.4946e-01,  1.6657e-01,\n",
       "         3.5509e-02, -6.9762e-02, -6.8876e-01, -7.6955e-02, -4.1597e-01,\n",
       "         2.1833e-01, -5.0840e-02,  1.1012e-02, -8.4219e-01,  8.1732e-03,\n",
       "         2.3076e-01, -1.3471e-01, -1.3804e-01, -1.7193e-01, -4.1916e-02,\n",
       "         4.6342e-02, -1.6927e-01,  1.2916e-01,  4.9892e-02, -1.7766e-04,\n",
       "         2.3980e-01, -1.2426e-02,  2.8921e-01,  7.6529e-02,  4.0428e-02,\n",
       "        -7.2281e-02,  2.7383e-02,  2.2038e-02,  7.4986e-03, -2.2034e-02,\n",
       "        -8.7478e-02,  1.4228e-01,  5.6342e-03, -1.4994e-02, -4.2508e-02,\n",
       "        -4.0388e-01, -4.2494e-02, -5.3632e-02, -1.6448e-01,  1.1655e-01,\n",
       "        -1.7038e-01, -1.4592e-01,  4.5876e-02, -1.9386e-01, -2.9255e-01,\n",
       "        -1.2719e-03,  2.2678e-01, -6.5934e-01, -1.0027e-01,  5.8857e-02,\n",
       "        -4.7171e-03, -2.5260e-01,  4.8024e-01,  2.5130e-01,  1.8917e-01,\n",
       "        -9.6679e-02,  2.9421e-01, -3.2499e-01,  3.2939e-02, -6.2388e-01,\n",
       "        -8.2636e-01,  4.7685e-02, -2.3763e-01,  1.1255e-02, -3.9774e-01,\n",
       "         4.5679e-02, -2.2334e-02,  5.5791e-01, -1.7342e-02, -3.1198e-01,\n",
       "        -3.1832e-01,  2.5811e-01,  5.0588e-01,  2.5590e-02,  1.3094e-02,\n",
       "        -5.3218e-04, -9.3628e-01,  9.8923e-01, -2.0474e-01,  6.8854e-02,\n",
       "         7.3004e-02,  1.5580e-01,  4.0277e-02, -3.6493e-01,  5.4078e-01,\n",
       "         8.3388e-01,  7.2386e-01,  9.1677e-02,  4.5870e-02,  2.1098e-01,\n",
       "        -6.8440e-03,  1.4706e-02, -8.4523e-01,  1.6198e-01,  9.7995e-01,\n",
       "         2.0520e-01, -1.4676e-01, -7.7989e-02, -5.2048e-02,  7.0038e-02,\n",
       "         3.5156e-02,  9.9403e-01,  1.6550e-02, -4.2307e-02,  9.3926e-01,\n",
       "        -9.2160e-03,  2.1514e-01,  3.8533e-02,  2.7757e-02, -1.6392e-01,\n",
       "        -4.5979e-01,  1.2630e-01, -1.5688e-01,  8.6976e-01,  6.3045e-02,\n",
       "         5.6099e-02, -7.8641e-02,  9.8894e-01, -2.4840e-02,  2.8251e-02,\n",
       "        -5.8718e-01, -1.4163e-01, -8.3281e-01,  9.6795e-03, -1.2812e-01,\n",
       "         3.1805e-02,  2.4579e-02, -5.5279e-02, -6.3164e-01, -3.2339e-02,\n",
       "        -2.1340e-01, -2.7064e-02,  4.6386e-01, -4.2922e-02,  6.9700e-01,\n",
       "        -2.1950e-01,  7.2755e-01,  1.3536e-02, -3.0217e-02,  3.2156e-01,\n",
       "        -4.5901e-01, -1.6994e-01, -3.0530e-02,  1.2922e-01, -2.9927e-01,\n",
       "        -8.0027e-02, -1.5399e-03,  1.2537e-01,  1.0282e-01, -6.9893e-02,\n",
       "         9.2142e-01,  9.8134e-01, -7.6018e-02,  4.3458e-01, -1.1109e-01,\n",
       "        -6.7204e-01, -3.5140e-02, -8.8391e-01, -2.7057e-02, -2.2747e-03,\n",
       "         9.8987e-01, -1.5296e-01, -9.3039e-01, -8.6909e-02,  1.8757e-01,\n",
       "        -1.7591e-01,  1.0885e-01, -3.1537e-02, -4.4804e-01,  2.9075e-02,\n",
       "        -1.5544e-01, -1.0409e-01, -2.3466e-01, -3.0629e-01, -9.1664e-01,\n",
       "         1.5165e-01, -5.4617e-02,  9.9444e-02, -1.7480e-01, -1.0111e-02,\n",
       "        -5.4449e-01,  6.3738e-02,  7.7780e-03, -1.5805e-01,  2.1872e-01,\n",
       "         2.9848e-01, -2.2653e-01,  4.2070e-02, -8.6330e-02,  3.7531e-02,\n",
       "        -1.9123e-01,  1.9687e-01, -5.8780e-02, -6.9038e-02, -2.3163e-02,\n",
       "        -6.0593e-01, -8.7440e-01,  7.5284e-02,  3.0102e-01,  2.1734e-01,\n",
       "         1.5886e-01,  9.3345e-02,  7.4573e-01,  1.2387e-01, -5.0726e-02,\n",
       "        -3.2686e-02,  6.4481e-01, -2.2092e-01,  3.0291e-02,  8.7987e-01,\n",
       "         4.2618e-01,  5.3054e-02,  1.5607e-01, -1.1278e-01, -9.9678e-01,\n",
       "        -5.9270e-02,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembles_input[0][0][1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
